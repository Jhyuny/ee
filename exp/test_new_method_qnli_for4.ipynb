{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertModel, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#-- setting custom model\n",
    "total_l = 6\n",
    "trans_l = 4\n",
    "base_model = \"bert-base-uncased\"\n",
    "model_name = \"textattack/bert-base-uncased-QNLI\"\n",
    " \n",
    "#-- setting result name\n",
    "result_name = \"qnli_6_4\"\n",
    "model_save_path = f\"/mnt/aix7101/jeong/ee/{result_name}.pt\"\n",
    "\n",
    "#-- setting training\n",
    "train_strategy = \"low_lr\"  # 'freeze', 'low_lr', 'unfreeze'\n",
    "num_epoch = 10\n",
    "num_unfreeze = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_dataset(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 104743\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "train_dataset = load_dataset(\"glue\", \"qnli\", split=\"train\")\n",
    "\n",
    "# load validation dataset\n",
    "val_dataset = load_dataset(\"glue\", \"qnli\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'sentence', 'label', 'idx'],\n",
      "    num_rows: 5463\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout = nn.Dropout(p=0.1).to(device) # in BERT default 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, output_hidden_states=True).eval().to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig, BertForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class CustomBertSmall(nn.Module):\n",
    "    def __init__(self, teacher_model, total_layers=6, transplanted_layers=3):\n",
    "        super().__init__()\n",
    "        assert transplanted_layers < total_layers, \"Transplanted layers must be fewer than total layers\"\n",
    "        \n",
    "        self.hidden_size = teacher_model.config.hidden_size\n",
    "        self.total_layers = total_layers\n",
    "        self.transplanted_layers = transplanted_layers\n",
    "\n",
    "        # 그대로 복사할 레이어 인덱스 계산\n",
    "        transplanted_start = 12 - transplanted_layers\n",
    "        original_layer_indices = list(range(transplanted_start))[:total_layers - transplanted_layers]\n",
    "\n",
    "        # Embedding 복사\n",
    "        self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "        # 선택된 layer만 복사해서 재구성\n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "        for idx in original_layer_indices:\n",
    "            layer = teacher_model.bert.encoder.layer[idx]\n",
    "            self.encoder_layers.append(layer)\n",
    "\n",
    "        for idx in range(transplanted_start, 12):\n",
    "            layer = teacher_model.bert.encoder.layer[idx]\n",
    "            self.encoder_layers.append(layer)\n",
    "\n",
    "        # Pooler와 Classifier도 복사\n",
    "        self.pooler = teacher_model.bert.pooler\n",
    "        self.dropout = teacher_model.dropout  # from classifier head\n",
    "        self.classifier = teacher_model.classifier\n",
    "\n",
    "        self.activation = nn.Tanh()  # 여전히 pooler 내부에서도 사용되지만 보존\n",
    "\n",
    "    # CustomBertSmall에 hidden_states 옵션 추가\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "        hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            extended_attention_mask = attention_mask[:, None, None, :]\n",
    "            extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            extended_attention_mask = None\n",
    "\n",
    "        all_hidden = []  # 각 레이어 출력 저장\n",
    "        for layer in self.encoder_layers:\n",
    "            hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "            if output_hidden_states:\n",
    "                all_hidden.append(hidden_states)\n",
    "\n",
    "        pooled_output = self.pooler(hidden_states)\n",
    "        pooled_output = self.dropout(self.activation(pooled_output))\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            return logits, all_hidden\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"textattack/bert-base-uncased-ag-news\"\n",
    "\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(base_model, num_labels=2)\n",
    "\n",
    "small_model = CustomBertSmall(\n",
    "    teacher_model=teacher_model,\n",
    "    total_layers=total_l,\n",
    "    transplanted_layers=trans_l,  # 마지막 l개 레이어 복사\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [check] before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Small Model (QNLI): 100%|██████████| 5463/5463 [00:57<00:00, 95.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy of Bertbase: 91.54%\n",
      "\n",
      "✅ Accuracy of CustomBertSmall: 50.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for accuracy with QNLI task\n",
    "correct_base = 0\n",
    "correct_small = 0\n",
    "\n",
    "model.eval()\n",
    "small_model.eval()\n",
    "\n",
    "for item in tqdm(val_dataset, desc=\"Evaluating Small Model (QNLI)\"):\n",
    "    text1 = item[\"question\"]\n",
    "    text2 = item[\"sentence\"]\n",
    "    label = item[\"label\"]\n",
    "\n",
    "    # inputs for sentence pair\n",
    "    inputs = tokenizer(text1, text2, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Teacher model\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        logits = output.logits\n",
    "        pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Small model\n",
    "    with torch.no_grad():\n",
    "        small_logits = small_model(**inputs)\n",
    "        small_pred = torch.argmax(small_logits, dim=-1).item()\n",
    "\n",
    "    correct_base += int(pred == label)\n",
    "    correct_small += int(small_pred == label)\n",
    "\n",
    "# 최종 정확도 출력\n",
    "total = len(val_dataset)\n",
    "print(f\"\\n✅ Accuracy of Bertbase: {correct_base / total * 100:.2f}%\")\n",
    "print(f\"\\n✅ Accuracy of CustomBertSmall: {correct_small / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss, KLDivLoss\n",
    "\n",
    "def loss1(logits, labels):\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# Representation Matching Loss (MSE between CLS tokens)\n",
    "def loss2(student_hidden, teacher_hidden):\n",
    "    mse = MSELoss()\n",
    "    return mse(student_hidden, teacher_hidden)\n",
    "\n",
    "# DSR Loss (KL Divergence between sorted logits)\n",
    "def loss3(prev_logits, current_logits, tau=1.0):\n",
    "    z_prev = torch.sort(prev_logits, dim=-1)[0]\n",
    "    z_current = torch.sort(current_logits, dim=-1)[0]\n",
    "\n",
    "    p_prev = F.softmax(z_prev / tau, dim=-1)\n",
    "    p_current = F.log_softmax(z_current / tau, dim=-1)\n",
    "\n",
    "    kldiv = KLDivLoss(reduction='batchmean')\n",
    "    return (tau ** 2 / 2) * kldiv(p_current, p_prev)  # KL(p_prev || p_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cka(X: torch.Tensor, Y: torch.Tensor, eps=1e-8):\n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "\n",
    "    dot_product_similarity = (X.T @ Y).norm(p='fro') ** 2\n",
    "    normalization_x = (X.T @ X).norm(p='fro')\n",
    "    normalization_y = (Y.T @ Y).norm(p='fro')\n",
    "    return dot_product_similarity / (normalization_x * normalization_y + eps)\n",
    "\n",
    "def cka_delta_loss(h_teacher_bef, h_teacher_aft, h_student_bef, h_student_aft):\n",
    "    delta_t = h_teacher_aft - h_teacher_bef\n",
    "    delta_s = h_student_aft - h_student_bef\n",
    "    t = delta_t[:, 0, :]  # CLS\n",
    "    s = delta_s[:, 0, :]\n",
    "    return 1 - compute_cka(t, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, tokenizer, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            text1 = batch[\"question\"][0]\n",
    "            text2 = batch[\"sentence\"][0]\n",
    "            label = batch[\"label\"].item()\n",
    "\n",
    "            inputs = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            logits = model(**inputs)\n",
    "            pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "            correct += int(pred == label)\n",
    "            total += 1\n",
    "\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# labels = torch.tensor(train_dataset[\"label\"])\n",
    "# print(\"Label dtype:\", labels.dtype)\n",
    "# print(\"Label min:\", labels.min().item())\n",
    "# print(\"Label max:\", labels.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "def train_custom_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    teacher_model=None,\n",
    "    custom_loss=False,\n",
    "    strategy=\"freeze\",\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    base_lr=5e-5,\n",
    "    low_lr=5e-6,\n",
    "    k=3,\n",
    "    alpha=0.3,\n",
    "    unfreeze_epoch=1,\n",
    "    save_path=\"best_model.pt\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "):\n",
    "    model = model.to(device)\n",
    "    if custom_loss and teacher_model is None:\n",
    "        raise ValueError(\"teacher_model must be provided when using custom_loss=True\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "    if strategy == \"low_lr\":\n",
    "        optimizer_grouped = [\n",
    "            {\"params\": [p for l in model.encoder_layers[:-k] for p in l.parameters()], \"lr\": base_lr},\n",
    "            {\"params\": [p for l in model.encoder_layers[-k:] for p in l.parameters()], \"lr\": low_lr},\n",
    "            {\"params\": model.pooler.parameters(), \"lr\": base_lr},\n",
    "            {\"params\": model.classifier.parameters(), \"lr\": base_lr},\n",
    "        ]\n",
    "    else:\n",
    "        optimizer_grouped = model.parameters()\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped, lr=base_lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if strategy == \"freeze\":\n",
    "        for layer in model.encoder_layers[-k:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        if strategy == \"unfreeze\" and epoch == unfreeze_epoch:\n",
    "            print(\"--<Unfreezing last K layers>--\")\n",
    "            for layer in model.encoder_layers[-k:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            texts1 = batch[\"question\"]\n",
    "            texts2 = batch[\"sentence\"]\n",
    "            labels = batch[\"label\"]\n",
    "\n",
    "            tokenized = tokenizer(list(texts1), list(texts2), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            inputs = {k: v.to(device) for k, v in tokenized.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if custom_loss:\n",
    "                logits_small, student_hiddens = model(**inputs, output_hidden_states=True)\n",
    "                ce_loss = loss_fn(logits_small, labels)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(**inputs, output_hidden_states=True)\n",
    "                    h_teacher_bef = teacher_outputs.hidden_states[(-1)-(k+1)]\n",
    "                    h_teacher_aft = teacher_outputs.hidden_states[(-1)-k]\n",
    "\n",
    "                h_student_bef = student_hiddens[(-1)-(k+1)]\n",
    "                h_student_aft = student_hiddens[(-1)-k]\n",
    "\n",
    "                cka_loss = cka_delta_loss(h_teacher_bef, h_teacher_aft, h_student_bef, h_student_aft)\n",
    "                loss = ce_loss + alpha * cka_loss\n",
    "            else:\n",
    "                logits = model(**inputs)\n",
    "                loss = loss_fn(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Avg Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        acc = evaluate(model, val_loader, tokenizer, device)\n",
    "        print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ New best model saved with accuracy: {best_acc:.2f}% → {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 2359/6547 [01:47<03:05, 22.61it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  53%|█████▎    | 3439/6547 [02:36<02:27, 21.04it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  72%|███████▏  | 4702/6547 [03:35<01:22, 22.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  76%|███████▌  | 4972/6547 [03:48<01:08, 22.88it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  99%|█████████▉| 6489/6547 [04:58<00:02, 20.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:01<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 230.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 83.87%\n",
      "✅ New best model saved with accuracy: 83.87% → /mnt/aix7101/jeong/ee/qnli_6_4.pt\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 198/6547 [00:09<05:10, 20.47it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  12%|█▏        | 776/6547 [00:36<04:17, 22.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  57%|█████▋    | 3721/6547 [02:52<02:30, 18.77it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  70%|██████▉   | 4557/6547 [03:31<01:32, 21.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  93%|█████████▎| 6066/6547 [04:41<00:23, 20.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:03<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 231.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 84.46%\n",
      "✅ New best model saved with accuracy: 84.46% → /mnt/aix7101/jeong/ee/qnli_6_4.pt\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 431/6547 [00:19<04:58, 20.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  11%|█         | 695/6547 [00:32<04:22, 22.30it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  84%|████████▍ | 5506/6547 [04:14<00:46, 22.23it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  85%|████████▍ | 5557/6547 [04:16<00:45, 21.65it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  90%|█████████ | 5915/6547 [04:33<00:28, 22.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:03<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.2726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:24<00:00, 224.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 84.06%\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 164/6547 [00:07<04:57, 21.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:   9%|▉         | 611/6547 [00:28<04:40, 21.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  15%|█▌        | 1013/6547 [00:47<04:21, 21.20it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  40%|███▉      | 2587/6547 [01:59<03:00, 21.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  96%|█████████▌| 6282/6547 [04:51<00:12, 21.66it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:03<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:24<00:00, 225.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 82.48%\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 140/6547 [00:06<05:15, 20.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:   7%|▋         | 431/6547 [00:19<04:34, 22.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  34%|███▍      | 2217/6547 [01:42<03:31, 20.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  69%|██████▊   | 4493/6547 [03:28<01:36, 21.35it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  82%|████████▏ | 5352/6547 [04:08<00:52, 22.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:03<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 228.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 82.94%\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|███▋      | 2410/6547 [01:51<03:06, 22.22it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  40%|███▉      | 2591/6547 [02:00<03:08, 20.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  56%|█████▋    | 3693/6547 [02:51<02:11, 21.78it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  68%|██████▊   | 4476/6547 [03:27<01:36, 21.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  79%|███████▉  | 5175/6547 [04:00<01:03, 21.53it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:03<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 229.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 83.18%\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 232/6547 [00:10<04:43, 22.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  21%|██▏       | 1396/6547 [01:04<03:53, 22.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  45%|████▍     | 2944/6547 [02:16<02:44, 21.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  61%|██████    | 3991/6547 [03:05<01:59, 21.36it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  73%|███████▎  | 4750/6547 [03:40<01:30, 19.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:04<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 231.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 83.25%\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 725/6547 [00:33<04:44, 20.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  52%|█████▏    | 3401/6547 [02:37<02:25, 21.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  64%|██████▍   | 4184/6547 [03:13<01:44, 22.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  69%|██████▉   | 4548/6547 [03:31<01:28, 22.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:03<00:00, 21.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 230.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 82.88%\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 3700/6547 [02:51<02:13, 21.33it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  69%|██████▊   | 4486/6547 [03:28<01:37, 21.20it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  73%|███████▎  | 4757/6547 [03:40<01:20, 22.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  74%|███████▎  | 4826/6547 [03:44<01:18, 21.80it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  79%|███████▉  | 5198/6547 [04:01<01:02, 21.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:04<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.0730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 231.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 81.24%\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 2576/6547 [01:59<03:08, 21.04it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  70%|██████▉   | 4565/6547 [03:31<01:29, 22.20it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  72%|███████▏  | 4746/6547 [03:40<01:22, 21.76it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  85%|████████▍ | 5548/6547 [04:17<00:47, 21.18it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  89%|████████▉ | 5825/6547 [04:30<00:35, 20.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [05:04<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Training Loss: 0.0655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:23<00:00, 229.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 82.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_custom_model(\n",
    "    model=small_model,\n",
    "    teacher_model=model,   # 꼭 전달!\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    custom_loss=True,              # ✅ 사용\n",
    "    alpha=0.3,                     # CKA 가중치\n",
    "    k=trans_l,\n",
    "    strategy=\"train_strategy\",\n",
    "    unfreeze_epoch=num_unfreeze,\n",
    "    epochs=num_epoch,\n",
    "    save_path=model_save_path,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습 시작\n",
    "# train_custom_model(\n",
    "#     model=small_model,\n",
    "#     train_dataset=train_dataset,\n",
    "#     val_dataset=val_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     strategy=train_strategy,  # 'freeze', 'low_lr', 'unfreeze'\n",
    "#     epochs=num_epoch,\n",
    "#     batch_size=16,\n",
    "#     base_lr=5e-5,\n",
    "#     low_lr=5e-6,\n",
    "#     k=2,  # 마지막 3개 레이어를 보존\n",
    "#     unfreeze_epoch=num_unfreeze,\n",
    "#     save_path=model_save_path\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [check] after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Small Model on QNLI: 100%|██████████| 5463/5463 [00:57<00:00, 94.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy of Bertbase: 91.54%\n",
      "\n",
      "✅ Accuracy of CustomBertSmall: 84.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_base = 0\n",
    "correct_small = 0\n",
    "\n",
    "model.eval()\n",
    "small_model.eval()\n",
    "\n",
    "for item in tqdm(val_dataset, desc=\"Evaluating Small Model on QNLI\"):\n",
    "    question = item[\"question\"]\n",
    "    sentence = item[\"sentence\"]\n",
    "    label = item[\"label\"]\n",
    "\n",
    "    # QNLI는 sentence pair 입력\n",
    "    inputs = tokenizer(question, sentence, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Teacher model (BertForSequenceClassification)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        logits = output.logits\n",
    "        pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Small model (CustomBertSmall)\n",
    "    with torch.no_grad():\n",
    "        small_logits = small_model(**inputs)\n",
    "        small_pred = torch.argmax(small_logits, dim=-1).item()\n",
    "    \n",
    "    correct_base += int(pred == label)\n",
    "    correct_small += int(small_pred == label)\n",
    "\n",
    "# 정확도 출력\n",
    "total = len(val_dataset)\n",
    "print(f\"\\n✅ Accuracy of Bertbase: {correct_base / total * 100:.2f}%\")\n",
    "print(f\"\\n✅ Accuracy of CustomBertSmall: {correct_small / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 1: 100%|██████████| 5463/5463 [01:02<00:00, 87.55it/s]\n",
      "Layer 2: 100%|██████████| 5463/5463 [01:02<00:00, 88.05it/s]\n",
      "Layer 3: 100%|██████████| 5463/5463 [01:02<00:00, 87.14it/s]\n",
      "Layer 4: 100%|██████████| 5463/5463 [01:02<00:00, 87.42it/s]\n",
      "Layer 5: 100%|██████████| 5463/5463 [01:02<00:00, 87.93it/s]\n",
      "Layer 6: 100%|██████████| 5463/5463 [01:02<00:00, 87.78it/s]\n",
      "Layer 7: 100%|██████████| 5463/5463 [01:02<00:00, 87.88it/s]\n",
      "Layer 8: 100%|██████████| 5463/5463 [01:02<00:00, 87.87it/s]\n",
      "Layer 9: 100%|██████████| 5463/5463 [01:02<00:00, 87.82it/s]\n",
      "Layer 10: 100%|██████████| 5463/5463 [01:02<00:00, 87.53it/s]\n",
      "Layer 11: 100%|██████████| 5463/5463 [01:01<00:00, 88.20it/s]\n",
      "Layer 12: 100%|██████████| 5463/5463 [01:01<00:00, 88.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 저장 리스트\n",
    "acc_original = []\n",
    "acc_small = [0] * total_l  # ✅ small_model의 레이어 수만큼 정확도 저장\n",
    "\n",
    "for layer in range(1, 13):  # BERT-base: layer 1~12\n",
    "    correct_orig = 0\n",
    "    correct_small_by_layer = [0] * total_l  # 각 small layer의 정답 수\n",
    "    total = 0\n",
    "\n",
    "    for item in tqdm(val_dataset, desc=f\"Layer {layer}\"):\n",
    "        question = item[\"question\"]\n",
    "        sentence = item[\"sentence\"]\n",
    "        label = item[\"label\"]\n",
    "\n",
    "        # QNLI는 sentence pair 입력\n",
    "        inputs = tokenizer(question, sentence, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # BERT-base layer별 정확도\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden = outputs.hidden_states[layer]\n",
    "            pooled = model.bert.pooler(hidden)\n",
    "            pooled_dropped = dropout(pooled)\n",
    "            logits_orig = model.classifier(pooled_dropped)\n",
    "            pred_orig = torch.argmax(logits_orig, dim=-1).item()\n",
    "\n",
    "            # small model: 전체 forward + hidden states\n",
    "            logits_small, small_hidden_states = small_model(**inputs, output_hidden_states=True)\n",
    "\n",
    "            for i, h in enumerate(small_hidden_states):\n",
    "                pooled_small = small_model.pooler(h)  # CLS 포함\n",
    "                pooled_small = dropout(pooled_small)\n",
    "                logits = small_model.classifier(pooled_small)\n",
    "                pred = torch.argmax(logits, dim=-1).item()\n",
    "                correct_small_by_layer[i] += int(pred == label)\n",
    "\n",
    "            correct_orig += int(pred_orig == label)\n",
    "            total += 1\n",
    "\n",
    "    acc_original.append(correct_orig / total)\n",
    "\n",
    "    # 마지막 layer 기준에서 정확도 누적 (1 epoch 끝났을 때만 기록됨)\n",
    "    if layer == 12:\n",
    "        acc_small = [c / total for c in correct_small_by_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5048508145707487,\n",
       " 0.5061321618158521,\n",
       " 0.5048508145707487,\n",
       " 0.5916163280248947,\n",
       " 0.66630056745378,\n",
       " 0.6015010067728355,\n",
       " 0.6701446091890902,\n",
       " 0.6459820611385686,\n",
       " 0.6547684422478491,\n",
       " 0.780523521874428,\n",
       " 0.8345231557752151,\n",
       " 0.9157971810360608]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5053999633900788,\n",
       " 0.5061321618158521,\n",
       " 0.6247483067911404,\n",
       " 0.7603880651656599,\n",
       " 0.8253706754530478,\n",
       " 0.8460552809811459]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(range(1, 13), acc_original, label=\"BERT-base\", marker='o', linewidth=2)\n",
    "plt.plot(range(1, total_l + 1), acc_small, label=\"CustomBertSmall\", marker='x', linewidth=2)\n",
    "plt.xlabel(\"Layer Number\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Layer-wise Accuracy: BERT-base vs CustomBertSmall\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/home/aix7101/jeong/ee/ours/codes/img/{result_name}.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
