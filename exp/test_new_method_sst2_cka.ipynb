{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertModel, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#-- setting custom model\n",
    "total_l = 6\n",
    "trans_l = 1\n",
    "base_model = \"bert-base-uncased\"\n",
    "model_name = \"textattack/bert-base-uncased-SST-2\"\n",
    "task_name = \"sst2\"\n",
    "\n",
    "#-- setting result name\n",
    "result_name = \"sst2_cka\"\n",
    "model_save_path = f\"/mnt/aix7101/jeong/ee/{result_name}.pt\"\n",
    "\n",
    "#-- setting training\n",
    "train_strategy = \"low_lr\"  # 'freeze', 'low_lr', 'unfreeze'\n",
    "num_epoch = 10\n",
    "num_unfreeze = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "train_dataset = load_dataset(\"glue\", \"sst2\", split=\"train\")\n",
    "\n",
    "# load validation dataset\n",
    "val_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'label', 'idx'],\n",
      "    num_rows: 872\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout = nn.Dropout(p=0.1).to(device) # in BERT default 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, output_hidden_states=True).eval().to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertModel, BertConfig, BertForSequenceClassification\n",
    "# import torch.nn as nn\n",
    "# import torch\n",
    "\n",
    "# class CustomBertSmall(nn.Module):\n",
    "#     def __init__(self, teacher_model, total_layers=6, transplanted_layers=3):\n",
    "#         super().__init__()\n",
    "#         assert transplanted_layers < total_layers, \"Transplanted layers must be fewer than total layers\"\n",
    "        \n",
    "#         self.hidden_size = teacher_model.config.hidden_size\n",
    "#         self.total_layers = total_layers\n",
    "#         self.transplanted_layers = transplanted_layers\n",
    "\n",
    "#         # 그대로 복사할 레이어 인덱스 계산\n",
    "#         transplanted_start = 12 - transplanted_layers\n",
    "#         original_layer_indices = list(range(transplanted_start))[:total_layers - transplanted_layers]\n",
    "\n",
    "#         # Embedding 복사\n",
    "#         self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "#         # 선택된 layer만 복사해서 재구성\n",
    "#         self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "#         for idx in original_layer_indices:\n",
    "#             layer = teacher_model.bert.encoder.layer[idx]\n",
    "#             self.encoder_layers.append(layer)\n",
    "\n",
    "#         for idx in range(transplanted_start, 12):\n",
    "#             layer = teacher_model.bert.encoder.layer[idx]\n",
    "#             self.encoder_layers.append(layer)\n",
    "\n",
    "#         # Pooler와 Classifier도 복사\n",
    "#         self.pooler = teacher_model.bert.pooler\n",
    "#         self.dropout = teacher_model.dropout  # from classifier head\n",
    "#         self.classifier = teacher_model.classifier\n",
    "\n",
    "#         self.activation = nn.Tanh()  # 여전히 pooler 내부에서도 사용되지만 보존\n",
    "\n",
    "#     # CustomBertSmall에 hidden_states 옵션 추가\n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "#         hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "#         if attention_mask is not None:\n",
    "#             extended_attention_mask = attention_mask[:, None, None, :]\n",
    "#             extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "#         else:\n",
    "#             extended_attention_mask = None\n",
    "\n",
    "#         all_hidden = []  # 각 레이어 출력 저장\n",
    "#         for layer in self.encoder_layers:\n",
    "#             hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "#             if output_hidden_states:\n",
    "#                 all_hidden.append(hidden_states)\n",
    "\n",
    "#         pooled_output = self.pooler(hidden_states)\n",
    "#         pooled_output = self.dropout(self.activation(pooled_output))\n",
    "#         logits = self.classifier(pooled_output)\n",
    "\n",
    "#         if output_hidden_states:\n",
    "#             return logits, all_hidden\n",
    "#         else:\n",
    "#             return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomBertSmallForCKA(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = teacher_model.config.hidden_size\n",
    "        self.selected_layer_indices = [0, 1, 2, 3, 4, 11]  # 1-based: [1,2,3,4,5,12] → 0-based index\n",
    "\n",
    "        # Embedding 복사\n",
    "        self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "        # 선택된 레이어만 복사\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            teacher_model.bert.encoder.layer[idx] for idx in self.selected_layer_indices\n",
    "        ])\n",
    "\n",
    "        # Pooler와 Classifier는 그대로 복사\n",
    "        self.pooler = teacher_model.bert.pooler\n",
    "        self.dropout = teacher_model.dropout\n",
    "        self.classifier = teacher_model.classifier\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "        hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            extended_attention_mask = attention_mask[:, None, None, :]\n",
    "            extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            extended_attention_mask = None\n",
    "\n",
    "        all_hidden = []\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "            if output_hidden_states:\n",
    "                all_hidden.append(hidden_states)\n",
    "\n",
    "        pooled_output = self.pooler(hidden_states)\n",
    "        pooled_output = self.dropout(self.activation(pooled_output))\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            return logits, all_hidden\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"textattack/bert-base-uncased-ag-news\"\n",
    "\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "small_model = CustomBertSmallForCKA(\n",
    "    teacher_model=teacher_model \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [check] before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for accuracy with QQP task\n",
    "# correct_base = 0\n",
    "# correct_small = 0\n",
    "\n",
    "# model.eval()\n",
    "# small_model.eval()\n",
    "\n",
    "# for item in tqdm(val_dataset, desc=\"Evaluating Small Model (QQP)\"):\n",
    "#     text1 = item[\"sentence1\"]\n",
    "#     text2 = item[\"sentence2\"]\n",
    "#     label = item[\"label\"]\n",
    "\n",
    "#     # inputs for sentence pair\n",
    "#     inputs = tokenizer(text1, text2, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "#     # Teacher model\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**inputs)\n",
    "#         logits = output.logits\n",
    "#         pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "#     # Small model\n",
    "#     with torch.no_grad():\n",
    "#         small_logits = small_model(**inputs)\n",
    "#         small_pred = torch.argmax(small_logits, dim=-1).item()\n",
    "\n",
    "#     correct_base += int(pred == label)\n",
    "#     correct_small += int(small_pred == label)\n",
    "\n",
    "# # 최종 정확도 출력\n",
    "# total = len(val_dataset)\n",
    "# print(f\"\\n✅ Accuracy of Bertbase: {correct_base / total * 100:.2f}%\")\n",
    "# print(f\"\\n✅ Accuracy of CustomBertSmall: {correct_small / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss, KLDivLoss\n",
    "\n",
    "def loss1(logits, labels):\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# Representation Matching Loss (MSE between CLS tokens)\n",
    "def loss2(student_hidden, teacher_hidden):\n",
    "    mse = MSELoss()\n",
    "    return mse(student_hidden, teacher_hidden)\n",
    "\n",
    "# DSR Loss (KL Divergence between sorted logits)\n",
    "def loss3(prev_logits, current_logits, tau=1.0):\n",
    "    z_prev = torch.sort(prev_logits, dim=-1)[0]\n",
    "    z_current = torch.sort(current_logits, dim=-1)[0]\n",
    "\n",
    "    p_prev = F.softmax(z_prev / tau, dim=-1)\n",
    "    p_current = F.log_softmax(z_current / tau, dim=-1)\n",
    "\n",
    "    kldiv = KLDivLoss(reduction='batchmean')\n",
    "    return (tau ** 2 / 2) * kldiv(p_current, p_prev)  # KL(p_prev || p_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cka(X: torch.Tensor, Y: torch.Tensor, eps=1e-8):\n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "\n",
    "    dot_product_similarity = (X.T @ Y).norm(p='fro') ** 2\n",
    "    normalization_x = (X.T @ X).norm(p='fro')\n",
    "    normalization_y = (Y.T @ Y).norm(p='fro')\n",
    "    return dot_product_similarity / (normalization_x * normalization_y + eps)\n",
    "\n",
    "def cka_delta_loss(h_teacher_bef, h_teacher_aft, h_student_bef, h_student_aft):\n",
    "    delta_t = h_teacher_aft - h_teacher_bef\n",
    "    delta_s = h_student_aft - h_student_bef\n",
    "    t = delta_t[:, 0, :]  # CLS\n",
    "    s = delta_s[:, 0, :]\n",
    "    return 1 - compute_cka(t, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, tokenizer, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            text1 = batch[\"sentence1\"][0]\n",
    "            text2 = batch[\"sentence2\"][0]\n",
    "            label = batch[\"label\"].item()\n",
    "\n",
    "            inputs = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            logits = model(**inputs)\n",
    "            pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "            correct += int(pred == label)\n",
    "            total += 1\n",
    "\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_teacher_layers(n_student_layers, n_teacher_layers=12):\n",
    "    return np.linspace(1, n_teacher_layers, n_student_layers, dtype=int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_cka_loss_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    teacher_model=None,\n",
    "    custom_loss=False,  # CKA 전용 loss\n",
    "    strategy=\"freeze\",\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    base_lr=5e-5,\n",
    "    low_lr=5e-6,\n",
    "    k=3,\n",
    "    alpha=1.0,  # alpha는 의미 없음, loss = cka_loss 단일\n",
    "    unfreeze_epoch=1,\n",
    "    save_path=\"best_model.pt\",\n",
    "    device=\"cuda:1\" if torch.cuda.is_available() else \"cpu\",\n",
    "    evaluate_fn=None,\n",
    "    task_config=None\n",
    "):\n",
    "    if task_config is None:\n",
    "        raise ValueError(\"task_config must be provided.\")\n",
    "    if custom_loss and teacher_model is None:\n",
    "        raise ValueError(\"teacher_model must be provided when using custom_loss=True\")\n",
    "    if evaluate_fn is None:\n",
    "        raise ValueError(\"evaluate_fn must be provided for evaluation\")\n",
    "\n",
    "    input_keys = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    model = model.to(device)\n",
    "    teacher_model = teacher_model.to(device) if teacher_model else None\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "    if strategy == \"low_lr\":\n",
    "        optimizer_grouped = [\n",
    "            {\"params\": model.encoder_layers[0].parameters(), \"lr\": low_lr},   # ⬅️ 첫 번째 레이어\n",
    "            {\"params\": model.encoder_layers[-1].parameters(), \"lr\": low_lr},  # ⬅️ 마지막 레이어\n",
    "            {\"params\": [p for l in model.encoder_layers[1:-1] for p in l.parameters()], \"lr\": base_lr},\n",
    "            {\"params\": model.pooler.parameters(), \"lr\": base_lr},\n",
    "            {\"params\": model.classifier.parameters(), \"lr\": base_lr},\n",
    "        ]\n",
    "    else:\n",
    "        optimizer_grouped = model.parameters()  \n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped, lr=base_lr)\n",
    "\n",
    "    # 기본 loss는 CE지만, custom_loss=True일 경우 사용 안 함\n",
    "    loss_fn = nn.MSELoss() if task_type == \"regression\" else nn.CrossEntropyLoss()\n",
    "\n",
    "    if strategy == \"freeze\":\n",
    "        for layer in model.encoder_layers[-k:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    best_score = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"\\n📘 Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        if strategy == \"unfreeze\" and epoch == unfreeze_epoch:\n",
    "            print(\"--<Unfreezing last K layers>--\")\n",
    "            for layer in model.encoder_layers[-k:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            # 입력 처리\n",
    "            if len(input_keys) == 2:\n",
    "                texts1 = batch[input_keys[0]]\n",
    "                texts2 = batch[input_keys[1]]\n",
    "                tokenized = tokenizer(list(texts1), list(texts2), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            else:\n",
    "                texts = batch[input_keys[0]]\n",
    "                tokenized = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in tokenized.items()}\n",
    "            labels = batch[label_key].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if custom_loss:\n",
    "                # forward\n",
    "                logits_small, student_hiddens = model(**inputs, output_hidden_states=True)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(**inputs, output_hidden_states=True)\n",
    "                    teacher_hiddens = teacher_outputs.hidden_states  # 13개 (embedding 포함)\n",
    "\n",
    "                # layer 대응\n",
    "                s_h = student_hiddens[1:]  # skip embedding\n",
    "                t_indices = get_matched_teacher_layers(len(s_h), n_teacher_layers=12)\n",
    "                t_h = [teacher_hiddens[i] for i in t_indices]\n",
    "\n",
    "                # CLS 기준으로 CKA loss 계산\n",
    "                loss_cka = 0.0\n",
    "                for t, s in zip(t_h, s_h):\n",
    "                    t_cls = t[:, 0, :]\n",
    "                    s_cls = s[:, 0, :]\n",
    "                    loss_cka += 1 - compute_cka(t_cls, s_cls)\n",
    "                loss_cka /= len(s_h)\n",
    "                loss = loss_cka\n",
    "\n",
    "            else:\n",
    "                logits = model(**inputs)\n",
    "                if task_type == \"regression\":\n",
    "                    labels = labels.float()\n",
    "                    loss = loss_fn(logits.squeeze(), labels)\n",
    "                else:\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"📉 Avg Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        score = evaluate_fn(model, val_loader, tokenizer, device)\n",
    "        print(f\"📊 Validation Score: {score:.4f}\")\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ Best model saved with score: {best_score:.4f} → {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_TASKS = {\n",
    "    \"sst2\":  {\"inputs\": [\"sentence\"],                     \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-SST-2\"},\n",
    "    \"cola\":  {\"inputs\": [\"sentence\"],                     \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-CoLA\"},\n",
    "    \"qqp\":   {\"inputs\": [\"question1\", \"question2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-QQP\"},\n",
    "    \"qnli\":  {\"inputs\": [\"question\", \"sentence\"],         \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-QNLI\"},\n",
    "    \"mrpc\":  {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-MRPC\"},\n",
    "    \"rte\":   {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-RTE\"},\n",
    "    \"stsb\":  {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"regression\", \"model\": \"textattack/bert-base-uncased-STS-B\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def make_evaluate_fn(task_config):\n",
    "    inputs = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    def evaluate(model, val_loader, tokenizer, device):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "                if len(inputs) == 2:\n",
    "                    text1 = batch[inputs[0]][0]\n",
    "                    text2 = batch[inputs[1]][0]\n",
    "                    encoded = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "                else:\n",
    "                    text = batch[inputs[0]][0]\n",
    "                    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "                encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "                label = batch[label_key].item()\n",
    "                output = model(**encoded)\n",
    "\n",
    "                if task_type == \"regression\":\n",
    "                    pred = output.squeeze().cpu().item()\n",
    "                else:\n",
    "                    pred = torch.argmax(output, dim=-1).item()\n",
    "\n",
    "                preds.append(pred)\n",
    "                labels.append(label)\n",
    "\n",
    "        # 결과 계산\n",
    "        if task_type == \"regression\":\n",
    "            score = pearsonr(preds, labels)[0] * 100  # %\n",
    "        elif task_type in [\"binary\", \"3-class\"]:\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            if len(set(labels)) == 2:\n",
    "                f1 = f1_score(labels, preds)\n",
    "                score = (acc + f1) / 2 * 100\n",
    "            else:\n",
    "                score = acc * 100\n",
    "        else:\n",
    "            raise ValueError(\"Unknown task type\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    return evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "# from loss import cka_delta_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = GLUE_TASKS[task_name]\n",
    "\n",
    "evaluate_fn = make_evaluate_fn(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:25<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 132.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.1855\n",
      "✅ Best model saved with score: 89.1855 → /mnt/aix7101/jeong/ee/sst2_cka.pt\n",
      "\n",
      "📘 Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:25<00:00, 29.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 132.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.3041\n",
      "✅ Best model saved with score: 89.3041 → /mnt/aix7101/jeong/ee/sst2_cka.pt\n",
      "\n",
      "📘 Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:25<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 133.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.1857\n",
      "\n",
      "📘 Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:24<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 130.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.7490\n",
      "✅ Best model saved with score: 89.7490 → /mnt/aix7101/jeong/ee/sst2_cka.pt\n",
      "\n",
      "📘 Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:25<00:00, 29.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 131.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 90.3122\n",
      "✅ Best model saved with score: 90.3122 → /mnt/aix7101/jeong/ee/sst2_cka.pt\n",
      "\n",
      "📘 Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:24<00:00, 29.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 132.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.4013\n",
      "\n",
      "📘 Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:26<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 132.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 88.7553\n",
      "\n",
      "📘 Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:24<00:00, 29.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 132.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.2808\n",
      "\n",
      "📘 Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:24<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 130.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 88.6286\n",
      "\n",
      "📘 Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 4210/4210 [02:25<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 872/872 [00:06<00:00, 132.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 89.0312\n"
     ]
    }
   ],
   "source": [
    "train_cka_loss_model(\n",
    "    model=small_model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    teacher_model=model,\n",
    "    custom_loss=False,\n",
    "    strategy=\"low_lr\",\n",
    "    batch_size=16,\n",
    "    epochs=num_epoch,\n",
    "    k=trans_l,\n",
    "    unfreeze_epoch=num_unfreeze,\n",
    "    save_path=model_save_path,\n",
    "    evaluate_fn=evaluate_fn,\n",
    "    task_config=task_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "#-- load trained model\n",
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_teacher_student(\n",
    "    teacher_model,\n",
    "    student_model,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    task_config,\n",
    "    task_name=None  # 👈 task 이름 추가로 받음 (cola 확인용)\n",
    "):\n",
    "    inputs_key = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    teacher_model.eval()\n",
    "    student_model.eval()\n",
    "\n",
    "    preds_teacher = []\n",
    "    preds_student = []\n",
    "    labels = []\n",
    "\n",
    "    for item in tqdm(val_dataset, desc=\"Evaluating Teacher vs Student\"):\n",
    "        if len(inputs_key) == 2:\n",
    "            input_text1 = item[inputs_key[0]]\n",
    "            input_text2 = item[inputs_key[1]]\n",
    "            tokenized = tokenizer(input_text1, input_text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        else:\n",
    "            input_text = item[inputs_key[0]]\n",
    "            tokenized = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "        label = item[label_key]\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.item()\n",
    "        labels.append(label)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_logits = teacher_model(**tokenized)\n",
    "            t_pred = t_logits.logits.squeeze().item() if task_type == \"regression\" else torch.argmax(t_logits.logits, dim=-1).item()\n",
    "\n",
    "            s_logits = student_model(**tokenized)\n",
    "            s_pred = s_logits.squeeze().item() if task_type == \"regression\" else torch.argmax(s_logits, dim=-1).item()\n",
    "\n",
    "        preds_teacher.append(t_pred)\n",
    "        preds_student.append(s_pred)\n",
    "\n",
    "    # 🎯 점수 계산\n",
    "    if task_type == \"regression\":\n",
    "        pearson_t = pearsonr(preds_teacher, labels)[0] * 100\n",
    "        pearson_s = pearsonr(preds_student, labels)[0] * 100\n",
    "        print(f\"\\n✅ Pearson of Teacher: {pearson_t:.2f}%\")\n",
    "        print(f\"✅ Pearson of Student: {pearson_s:.2f}%\")\n",
    "\n",
    "    elif task_name == \"cola\":\n",
    "        mcc_t = matthews_corrcoef(labels, preds_teacher) * 100\n",
    "        mcc_s = matthews_corrcoef(labels, preds_student) * 100\n",
    "        print(f\"\\n✅ MCC of Teacher: {mcc_t:.2f}%\")\n",
    "        print(f\"✅ MCC of Student: {mcc_s:.2f}%\")\n",
    "\n",
    "    else:\n",
    "        acc_t = accuracy_score(labels, preds_teacher) * 100\n",
    "        acc_s = accuracy_score(labels, preds_student) * 100\n",
    "        print(f\"\\n✅ Accuracy of Teacher: {acc_t:.2f}%\")\n",
    "        print(f\"✅ Accuracy of Student: {acc_s:.2f}%\")\n",
    "    return acc_t, acc_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': ['sentence'], 'label': 'label', 'type': 'binary', 'model': 'textattack/bert-base-uncased-SST-2'}\n"
     ]
    }
   ],
   "source": [
    "print(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Teacher vs Student: 100%|██████████| 872/872 [00:15<00:00, 56.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy of Teacher: 92.43%\n",
      "✅ Accuracy of Student: 90.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.43119266055045, 90.13761467889908)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_teacher_student(\n",
    "    teacher_model=model,\n",
    "    student_model=small_model,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    task_config=task_config,\n",
    "    task_name=task_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
