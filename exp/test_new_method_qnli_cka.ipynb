{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertModel, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#-- setting custom model\n",
    "total_l = 6\n",
    "trans_l = 1\n",
    "base_model = \"bert-base-uncased\"\n",
    "model_name = \"textattack/bert-base-uncased-QNLI\"\n",
    "task_name = \"qnli\"\n",
    "\n",
    "#-- setting result name\n",
    "result_name = \"qnli_cka\"\n",
    "model_save_path = f\"/mnt/aix7101/jeong/ee/{result_name}.pt\"\n",
    "\n",
    "#-- setting training\n",
    "train_strategy = \"low_lr\"  # 'freeze', 'low_lr', 'unfreeze'\n",
    "num_epoch = 3\n",
    "num_unfreeze = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_dataset(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 104743\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "train_dataset = load_dataset(\"glue\", \"qnli\", split=\"train\")\n",
    "\n",
    "# load validation dataset\n",
    "val_dataset = load_dataset(\"glue\", \"qnli\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'sentence', 'label', 'idx'],\n",
      "    num_rows: 5463\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout = nn.Dropout(p=0.1).to(device) # in BERT default 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# setting\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:4399\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4390\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4392\u001b[0m     (\n\u001b[1;32m   4393\u001b[0m         model,\n\u001b[1;32m   4394\u001b[0m         missing_keys,\n\u001b[1;32m   4395\u001b[0m         unexpected_keys,\n\u001b[1;32m   4396\u001b[0m         mismatched_keys,\n\u001b[1;32m   4397\u001b[0m         offload_index,\n\u001b[1;32m   4398\u001b[0m         error_msgs,\n\u001b[0;32m-> 4399\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4408\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4417\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4418\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:4822\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4820\u001b[0m \u001b[38;5;66;03m# If shard_file is \"\", we use the existing state_dict instead of loading it\u001b[39;00m\n\u001b[1;32m   4821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 4822\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\n\u001b[1;32m   4824\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4826\u001b[0m \u001b[38;5;66;03m# Fix the key names\u001b[39;00m\n\u001b[1;32m   4827\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {key_renaming_mapping[k]: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key_renaming_mapping}\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:556\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(checkpoint_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m map_location \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_zipfile(checkpoint_file)\n\u001b[1;32m    554\u001b[0m     ):\n\u001b[1;32m    555\u001b[0m         extra_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/torch/serialization.py:1264\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m deserialized_objects\n\u001b[1;32m   1263\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m deserialized_objects[key]\n\u001b[0;32m-> 1264\u001b[0m \u001b[43mtyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_untyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_should_read_directly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1268\u001b[0m     offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setting\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, output_hidden_states=True).eval().to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertModel, BertConfig, BertForSequenceClassification\n",
    "# import torch.nn as nn\n",
    "# import torch\n",
    "\n",
    "# class CustomBertSmall(nn.Module):\n",
    "#     def __init__(self, teacher_model, total_layers=6, transplanted_layers=3):\n",
    "#         super().__init__()\n",
    "#         assert transplanted_layers < total_layers, \"Transplanted layers must be fewer than total layers\"\n",
    "        \n",
    "#         self.hidden_size = teacher_model.config.hidden_size\n",
    "#         self.total_layers = total_layers\n",
    "#         self.transplanted_layers = transplanted_layers\n",
    "\n",
    "#         # Í∑∏ÎåÄÎ°ú Î≥µÏÇ¨Ìï† Î†àÏù¥Ïñ¥ Ïù∏Îç±Ïä§ Í≥ÑÏÇ∞\n",
    "#         transplanted_start = 12 - transplanted_layers\n",
    "#         original_layer_indices = list(range(transplanted_start))[:total_layers - transplanted_layers]\n",
    "\n",
    "#         # Embedding Î≥µÏÇ¨\n",
    "#         self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "#         # ÏÑ†ÌÉùÎêú layerÎßå Î≥µÏÇ¨Ìï¥ÏÑú Ïû¨Íµ¨ÏÑ±\n",
    "#         self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "#         for idx in original_layer_indices:\n",
    "#             layer = teacher_model.bert.encoder.layer[idx]\n",
    "#             self.encoder_layers.append(layer)\n",
    "\n",
    "#         for idx in range(transplanted_start, 12):\n",
    "#             layer = teacher_model.bert.encoder.layer[idx]\n",
    "#             self.encoder_layers.append(layer)\n",
    "\n",
    "#         # PoolerÏôÄ ClassifierÎèÑ Î≥µÏÇ¨\n",
    "#         self.pooler = teacher_model.bert.pooler\n",
    "#         self.dropout = teacher_model.dropout  # from classifier head\n",
    "#         self.classifier = teacher_model.classifier\n",
    "\n",
    "#         self.activation = nn.Tanh()  # Ïó¨Ï†ÑÌûà pooler ÎÇ¥Î∂ÄÏóêÏÑúÎèÑ ÏÇ¨Ïö©ÎêòÏßÄÎßå Î≥¥Ï°¥\n",
    "\n",
    "#     # CustomBertSmallÏóê hidden_states ÏòµÏÖò Ï∂îÍ∞Ä\n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "#         hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "#         if attention_mask is not None:\n",
    "#             extended_attention_mask = attention_mask[:, None, None, :]\n",
    "#             extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "#         else:\n",
    "#             extended_attention_mask = None\n",
    "\n",
    "#         all_hidden = []  # Í∞Å Î†àÏù¥Ïñ¥ Ï∂úÎ†• Ï†ÄÏû•\n",
    "#         for layer in self.encoder_layers:\n",
    "#             hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "#             if output_hidden_states:\n",
    "#                 all_hidden.append(hidden_states)\n",
    "\n",
    "#         pooled_output = self.pooler(hidden_states)\n",
    "#         pooled_output = self.dropout(self.activation(pooled_output))\n",
    "#         logits = self.classifier(pooled_output)\n",
    "\n",
    "#         if output_hidden_states:\n",
    "#             return logits, all_hidden\n",
    "#         else:\n",
    "#             return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomBertSmallForCKA(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = teacher_model.config.hidden_size\n",
    "        self.selected_layer_indices = [0, 1, 2, 3, 4, 11]   # 1-based: [1,2,3,4,5,12] ‚Üí 0-based index\n",
    "\n",
    "        # Embedding Î≥µÏÇ¨\n",
    "        self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "        # ÏÑ†ÌÉùÎêú Î†àÏù¥Ïñ¥Îßå Î≥µÏÇ¨\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            teacher_model.bert.encoder.layer[idx] for idx in self.selected_layer_indices\n",
    "        ])\n",
    "\n",
    "        # PoolerÏôÄ ClassifierÎäî Í∑∏ÎåÄÎ°ú Î≥µÏÇ¨\n",
    "        self.pooler = teacher_model.bert.pooler\n",
    "        self.dropout = teacher_model.dropout\n",
    "        self.classifier = teacher_model.classifier\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "        hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            extended_attention_mask = attention_mask[:, None, None, :]\n",
    "            extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            extended_attention_mask = None\n",
    "\n",
    "        all_hidden = []\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "            if output_hidden_states:\n",
    "                all_hidden.append(hidden_states)\n",
    "\n",
    "        pooled_output = self.pooler(hidden_states)\n",
    "        pooled_output = self.dropout(self.activation(pooled_output))\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            return logits, all_hidden\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"textattack/bert-base-uncased-ag-news\"\n",
    "\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "small_model = CustomBertSmallForCKA(\n",
    "    teacher_model=teacher_model \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [check] before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for accuracy with QQP task\n",
    "# correct_base = 0\n",
    "# correct_small = 0\n",
    "\n",
    "# model.eval()\n",
    "# small_model.eval()\n",
    "\n",
    "# for item in tqdm(val_dataset, desc=\"Evaluating Small Model (QQP)\"):\n",
    "#     text1 = item[\"sentence1\"]\n",
    "#     text2 = item[\"sentence2\"]\n",
    "#     label = item[\"label\"]\n",
    "\n",
    "#     # inputs for sentence pair\n",
    "#     inputs = tokenizer(text1, text2, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "#     # Teacher model\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**inputs)\n",
    "#         logits = output.logits\n",
    "#         pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "#     # Small model\n",
    "#     with torch.no_grad():\n",
    "#         small_logits = small_model(**inputs)\n",
    "#         small_pred = torch.argmax(small_logits, dim=-1).item()\n",
    "\n",
    "#     correct_base += int(pred == label)\n",
    "#     correct_small += int(small_pred == label)\n",
    "\n",
    "# # ÏµúÏ¢Ö Ï†ïÌôïÎèÑ Ï∂úÎ†•\n",
    "# total = len(val_dataset)\n",
    "# print(f\"\\n‚úÖ Accuracy of Bertbase: {correct_base / total * 100:.2f}%\")\n",
    "# print(f\"\\n‚úÖ Accuracy of CustomBertSmall: {correct_small / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss, KLDivLoss\n",
    "\n",
    "def loss1(logits, labels):\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# Representation Matching Loss (MSE between CLS tokens)\n",
    "def loss2(student_hidden, teacher_hidden):\n",
    "    mse = MSELoss()\n",
    "    return mse(student_hidden, teacher_hidden)\n",
    "\n",
    "# DSR Loss (KL Divergence between sorted logits)\n",
    "def loss3(prev_logits, current_logits, tau=1.0):\n",
    "    z_prev = torch.sort(prev_logits, dim=-1)[0]\n",
    "    z_current = torch.sort(current_logits, dim=-1)[0]\n",
    "\n",
    "    p_prev = F.softmax(z_prev / tau, dim=-1)\n",
    "    p_current = F.log_softmax(z_current / tau, dim=-1)\n",
    "\n",
    "    kldiv = KLDivLoss(reduction='batchmean')\n",
    "    return (tau ** 2 / 2) * kldiv(p_current, p_prev)  # KL(p_prev || p_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cka(X: torch.Tensor, Y: torch.Tensor, eps=1e-8):\n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "\n",
    "    dot_product_similarity = (X.T @ Y).norm(p='fro') ** 2\n",
    "    normalization_x = (X.T @ X).norm(p='fro')\n",
    "    normalization_y = (Y.T @ Y).norm(p='fro')\n",
    "    return dot_product_similarity / (normalization_x * normalization_y + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, tokenizer, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            text1 = batch[\"sentence1\"][0]\n",
    "            text2 = batch[\"sentence2\"][0]\n",
    "            label = batch[\"label\"].item()\n",
    "\n",
    "            inputs = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            logits = model(**inputs)\n",
    "            pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "            correct += int(pred == label)\n",
    "            total += 1\n",
    "\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_teacher_layers(n_student_layers, n_teacher_layers=12):\n",
    "    return np.linspace(1, n_teacher_layers, n_student_layers, dtype=int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_cka_loss_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    teacher_model=None,\n",
    "    custom_loss=False,  # CKA Ï†ÑÏö© loss\n",
    "    strategy=\"freeze\",\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    base_lr=5e-5,\n",
    "    low_lr=5e-6,\n",
    "    k=3,\n",
    "    alpha=1.0,  # alphaÎäî ÏùòÎØ∏ ÏóÜÏùå, loss = cka_loss Îã®Ïùº\n",
    "    unfreeze_epoch=1,\n",
    "    save_path=\"best_model.pt\",\n",
    "    device=\"cuda:1\" if torch.cuda.is_available() else \"cpu\",\n",
    "    evaluate_fn=None,\n",
    "    task_config=None\n",
    "):\n",
    "    if task_config is None:\n",
    "        raise ValueError(\"task_config must be provided.\")\n",
    "    if custom_loss and teacher_model is None:\n",
    "        raise ValueError(\"teacher_model must be provided when using custom_loss=True\")\n",
    "    if evaluate_fn is None:\n",
    "        raise ValueError(\"evaluate_fn must be provided for evaluation\")\n",
    "\n",
    "    input_keys = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    model = model.to(device)\n",
    "    teacher_model = teacher_model.to(device) if teacher_model else None\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "    if strategy == \"low_lr\":\n",
    "        optimizer_grouped = [\n",
    "            {\"params\": model.encoder_layers[0].parameters(), \"lr\": low_lr},   # ‚¨ÖÔ∏è Ï≤´ Î≤àÏß∏ Î†àÏù¥Ïñ¥\n",
    "            {\"params\": model.encoder_layers[-1].parameters(), \"lr\": low_lr},  # ‚¨ÖÔ∏è ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥\n",
    "            {\"params\": [p for l in model.encoder_layers[1:-1] for p in l.parameters()], \"lr\": base_lr},\n",
    "            {\"params\": model.pooler.parameters(), \"lr\": base_lr},\n",
    "            {\"params\": model.classifier.parameters(), \"lr\": base_lr},\n",
    "        ]\n",
    "    else:\n",
    "        optimizer_grouped = model.parameters()  \n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped, lr=base_lr)\n",
    "\n",
    "    # Í∏∞Î≥∏ lossÎäî CEÏßÄÎßå, custom_loss=TrueÏùº Í≤ΩÏö∞ ÏÇ¨Ïö© Ïïà Ìï®\n",
    "    loss_fn = nn.MSELoss() if task_type == \"regression\" else nn.CrossEntropyLoss()\n",
    "\n",
    "    if strategy == \"freeze\":\n",
    "        for layer in model.encoder_layers[-k:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    best_score = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"\\nüìò Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        if strategy == \"unfreeze\" and epoch == unfreeze_epoch:\n",
    "            print(\"--<Unfreezing last K layers>--\")\n",
    "            for layer in model.encoder_layers[-k:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            # ÏûÖÎ†• Ï≤òÎ¶¨\n",
    "            if len(input_keys) == 2:\n",
    "                texts1 = batch[input_keys[0]]\n",
    "                texts2 = batch[input_keys[1]]\n",
    "                tokenized = tokenizer(list(texts1), list(texts2), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            else:\n",
    "                texts = batch[input_keys[0]]\n",
    "                tokenized = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in tokenized.items()}\n",
    "            labels = batch[label_key].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if custom_loss:\n",
    "                # forward\n",
    "                logits_small, student_hiddens = model(**inputs, output_hidden_states=True)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(**inputs, output_hidden_states=True)\n",
    "                    teacher_hiddens = teacher_outputs.hidden_states  # 13Í∞ú (embedding Ìè¨Ìï®)\n",
    "\n",
    "                # layer ÎåÄÏùë\n",
    "                s_h = student_hiddens[1:]  # skip embedding\n",
    "                t_indices = get_matched_teacher_layers(len(s_h), n_teacher_layers=12)\n",
    "                t_h = [teacher_hiddens[i] for i in t_indices]\n",
    "\n",
    "                # CLS Í∏∞Ï§ÄÏúºÎ°ú CKA loss Í≥ÑÏÇ∞\n",
    "                loss_cka = 0.0\n",
    "                for t, s in zip(t_h, s_h):\n",
    "                    t_cls = t[:, 0, :]\n",
    "                    s_cls = s[:, 0, :]\n",
    "                    loss_cka += 1 - compute_cka(t_cls, s_cls)\n",
    "                loss_cka /= len(s_h)\n",
    "                loss = loss_cka\n",
    "\n",
    "            else:\n",
    "                logits = model(**inputs)\n",
    "                if task_type == \"regression\":\n",
    "                    labels = labels.float()\n",
    "                    loss = loss_fn(logits.squeeze(), labels)\n",
    "                else:\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"üìâ Avg Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        score = evaluate_fn(model, val_loader, tokenizer, device)\n",
    "        print(f\"üìä Validation Score: {score:.4f}\")\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"‚úÖ Best model saved with score: {best_score:.4f} ‚Üí {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_TASKS = {\n",
    "    \"sst2\":  {\"inputs\": [\"sentence\"],                     \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-SST-2\"},\n",
    "    \"cola\":  {\"inputs\": [\"sentence\"],                     \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-CoLA\"},\n",
    "    \"qqp\":   {\"inputs\": [\"question1\", \"question2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-QQP\"},\n",
    "    \"qnli\":  {\"inputs\": [\"question\", \"sentence\"],         \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-QNLI\"},\n",
    "    \"mrpc\":  {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-MRPC\"},\n",
    "    \"rte\":   {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-RTE\"},\n",
    "    \"stsb\":  {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"regression\", \"model\": \"textattack/bert-base-uncased-STS-B\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def make_evaluate_fn(task_config):\n",
    "    inputs = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    def evaluate(model, val_loader, tokenizer, device):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "                if len(inputs) == 2:\n",
    "                    text1 = batch[inputs[0]][0]\n",
    "                    text2 = batch[inputs[1]][0]\n",
    "                    encoded = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "                else:\n",
    "                    text = batch[inputs[0]][0]\n",
    "                    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "                encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "                label = batch[label_key].item()\n",
    "                output = model(**encoded)\n",
    "\n",
    "                if task_type == \"regression\":\n",
    "                    pred = output.squeeze().cpu().item()\n",
    "                else:\n",
    "                    pred = torch.argmax(output, dim=-1).item()\n",
    "\n",
    "                preds.append(pred)\n",
    "                labels.append(label)\n",
    "\n",
    "        # Í≤∞Í≥º Í≥ÑÏÇ∞\n",
    "        if task_type == \"regression\":\n",
    "            score = pearsonr(preds, labels)[0] * 100  # %\n",
    "        elif task_type in [\"binary\", \"3-class\"]:\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            if len(set(labels)) == 2:\n",
    "                f1 = f1_score(labels, preds)\n",
    "                score = (acc + f1) / 2 * 100\n",
    "            else:\n",
    "                score = acc * 100\n",
    "        else:\n",
    "            raise ValueError(\"Unknown task type\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    return evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "# from loss import cka_delta_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = GLUE_TASKS[task_name]\n",
    "\n",
    "evaluate_fn = make_evaluate_fn(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|‚ñè         | 147/6547 [00:06<05:04, 21.02it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  32%|‚ñà‚ñà‚ñà‚ñè      | 2078/6547 [01:25<02:55, 25.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3320/6547 [02:16<02:11, 24.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 4232/6547 [02:54<01:31, 25.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4499/6547 [03:05<01:21, 24.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:29<00:00, 24.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 152.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.6077\n",
      "‚úÖ Best model saved with score: 87.6077 ‚Üí /mnt/aix7101/jeong/ee/qnli_cak.pt\n",
      "\n",
      "üìò Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|‚ñâ         | 651/6547 [00:26<03:58, 24.71it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5042/6547 [03:28<01:01, 24.67it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5315/6547 [03:39<00:49, 24.74it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5354/6547 [03:41<00:48, 24.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 6284/6547 [04:19<00:10, 24.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:30<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.2530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 152.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.7796\n",
      "‚úÖ Best model saved with score: 87.7796 ‚Üí /mnt/aix7101/jeong/ee/qnli_cak.pt\n",
      "\n",
      "üìò Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|‚ñà‚ñà‚ñé       | 1533/6547 [01:02<03:24, 24.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3081/6547 [02:06<02:21, 24.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 4103/6547 [02:49<01:38, 24.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4946/6547 [03:24<01:04, 24.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 6288/6547 [04:20<00:10, 24.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:30<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 152.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.5264\n",
      "\n",
      "üìò Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|‚ñç         | 288/6547 [00:11<04:12, 24.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  28%|‚ñà‚ñà‚ñä       | 1809/6547 [01:14<03:09, 25.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3390/6547 [02:20<02:30, 20.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3644/6547 [02:31<02:00, 24.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 5160/6547 [03:34<00:57, 24.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:33<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 153.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 86.1633\n",
      "\n",
      "üìò Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|‚ñà‚ñà‚ñã       | 1735/6547 [01:11<03:34, 22.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3634/6547 [02:30<02:00, 24.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4426/6547 [03:04<01:26, 24.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4780/6547 [03:18<01:10, 25.08it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 5488/6547 [03:48<00:42, 25.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:31<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 152.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.1776\n",
      "\n",
      "üìò Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|‚ñà‚ñà‚ñé       | 1478/6547 [01:01<03:26, 24.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 2424/6547 [01:40<02:46, 24.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  40%|‚ñà‚ñà‚ñà‚ñà      | 2640/6547 [01:49<02:39, 24.47it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2969/6547 [02:03<02:26, 24.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5622/6547 [03:54<00:37, 24.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:33<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:36<00:00, 151.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.1403\n",
      "\n",
      "üìò Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|‚ñà‚ñâ        | 1250/6547 [00:52<03:28, 25.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 4474/6547 [03:08<01:23, 24.70it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4879/6547 [03:24<01:06, 25.10it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5668/6547 [03:58<00:34, 25.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 6397/6547 [04:28<00:06, 23.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:34<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:36<00:00, 150.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.0171\n",
      "\n",
      "üìò Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|‚ñà‚ñà‚ñç       | 1628/6547 [01:08<03:52, 21.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  25%|‚ñà‚ñà‚ñå       | 1653/6547 [01:09<03:41, 22.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 4323/6547 [03:00<01:32, 24.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5307/6547 [03:42<00:49, 25.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5819/6547 [04:03<00:32, 22.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:34<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:36<00:00, 151.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 86.7216\n",
      "\n",
      "üìò Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|‚ñà         | 675/6547 [00:27<03:59, 24.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  29%|‚ñà‚ñà‚ñâ       | 1886/6547 [01:18<03:18, 23.45it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 5281/6547 [03:38<00:50, 25.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 5584/6547 [03:51<00:39, 24.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5850/6547 [04:02<00:29, 23.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:31<00:00, 24.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 153.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 86.8777\n",
      "\n",
      "üìò Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|‚ñà‚ñà‚ñå       | 1647/6547 [01:07<03:39, 22.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  37%|‚ñà‚ñà‚ñà‚ñã      | 2397/6547 [01:38<02:44, 25.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 3165/6547 [02:10<02:19, 24.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3929/6547 [02:42<01:58, 22.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 5002/6547 [03:28<01:02, 24.86it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6547/6547 [04:32<00:00, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Avg Training Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [00:35<00:00, 152.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Validation Score: 87.3821\n"
     ]
    }
   ],
   "source": [
    "train_cka_loss_model(\n",
    "    model=small_model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    teacher_model=model,\n",
    "    custom_loss=False,\n",
    "    strategy=\"low_lr\",\n",
    "    batch_size=16,\n",
    "    epochs=num_epoch,\n",
    "    k=trans_l,\n",
    "    unfreeze_epoch=num_unfreeze,\n",
    "    save_path=model_save_path,\n",
    "    evaluate_fn=evaluate_fn,\n",
    "    task_config=task_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "#-- load trained model\n",
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_teacher_student(\n",
    "    teacher_model,\n",
    "    student_model,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    task_config,\n",
    "    task_name=None  # üëà task Ïù¥Î¶Ñ Ï∂îÍ∞ÄÎ°ú Î∞õÏùå (cola ÌôïÏù∏Ïö©)\n",
    "):\n",
    "    inputs_key = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    teacher_model.eval()\n",
    "    student_model.eval()\n",
    "\n",
    "    preds_teacher = []\n",
    "    preds_student = []\n",
    "    labels = []\n",
    "\n",
    "    for item in tqdm(val_dataset, desc=\"Evaluating Teacher vs Student\"):\n",
    "        if len(inputs_key) == 2:\n",
    "            input_text1 = item[inputs_key[0]]\n",
    "            input_text2 = item[inputs_key[1]]\n",
    "            tokenized = tokenizer(input_text1, input_text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        else:\n",
    "            input_text = item[inputs_key[0]]\n",
    "            tokenized = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "        label = item[label_key]\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.item()\n",
    "        labels.append(label)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_logits = teacher_model(**tokenized)\n",
    "            t_pred = t_logits.logits.squeeze().item() if task_type == \"regression\" else torch.argmax(t_logits.logits, dim=-1).item()\n",
    "\n",
    "            s_logits = student_model(**tokenized)\n",
    "            s_pred = s_logits.squeeze().item() if task_type == \"regression\" else torch.argmax(s_logits, dim=-1).item()\n",
    "\n",
    "        preds_teacher.append(t_pred)\n",
    "        preds_student.append(s_pred)\n",
    "\n",
    "    # üéØ Ï†êÏàò Í≥ÑÏÇ∞\n",
    "    if task_type == \"regression\":\n",
    "        pearson_t = pearsonr(preds_teacher, labels)[0] * 100\n",
    "        pearson_s = pearsonr(preds_student, labels)[0] * 100\n",
    "        print(f\"\\n‚úÖ Pearson of Teacher: {pearson_t:.2f}%\")\n",
    "        print(f\"‚úÖ Pearson of Student: {pearson_s:.2f}%\")\n",
    "\n",
    "    elif task_name == \"cola\":\n",
    "        mcc_t = matthews_corrcoef(labels, preds_teacher) * 100\n",
    "        mcc_s = matthews_corrcoef(labels, preds_student) * 100\n",
    "        print(f\"\\n‚úÖ MCC of Teacher: {mcc_t:.2f}%\")\n",
    "        print(f\"‚úÖ MCC of Student: {mcc_s:.2f}%\")\n",
    "\n",
    "    else:\n",
    "        acc_t = accuracy_score(labels, preds_teacher) * 100\n",
    "        acc_s = accuracy_score(labels, preds_student) * 100\n",
    "        print(f\"\\n‚úÖ Accuracy of Teacher: {acc_t:.2f}%\")\n",
    "        print(f\"‚úÖ Accuracy of Student: {acc_s:.2f}%\")\n",
    "    return acc_t, acc_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Teacher vs Student: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5463/5463 [01:26<00:00, 63.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Accuracy of Teacher: 91.54%\n",
      "‚úÖ Accuracy of Student: 87.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.54310818231741, 87.60754164378547)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_teacher_student(\n",
    "    teacher_model=model,\n",
    "    student_model=small_model,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    task_config=task_config,\n",
    "    task_name=task_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
