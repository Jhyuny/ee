{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertModel, BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#-- setting custom model\n",
    "total_l = 6\n",
    "trans_l = 1\n",
    "base_model = \"bert-base-uncased\"\n",
    "model_name = \"textattack/bert-base-uncased-QNLI\"\n",
    "task_name = \"qnli\"\n",
    "\n",
    "#-- setting result name\n",
    "result_name = \"qnli_cka\"\n",
    "model_save_path = f\"/mnt/aix7101/jeong/ee/{result_name}.pt\"\n",
    "\n",
    "#-- setting training\n",
    "train_strategy = \"low_lr\"  # 'freeze', 'low_lr', 'unfreeze'\n",
    "num_epoch = 3\n",
    "num_unfreeze = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_dataset(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 104743\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "train_dataset = load_dataset(\"glue\", \"qnli\", split=\"train\")\n",
    "\n",
    "# load validation dataset\n",
    "val_dataset = load_dataset(\"glue\", \"qnli\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'sentence', 'label', 'idx'],\n",
      "    num_rows: 5463\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout = nn.Dropout(p=0.1).to(device) # in BERT default 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# setting\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:4399\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4390\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4392\u001b[0m     (\n\u001b[1;32m   4393\u001b[0m         model,\n\u001b[1;32m   4394\u001b[0m         missing_keys,\n\u001b[1;32m   4395\u001b[0m         unexpected_keys,\n\u001b[1;32m   4396\u001b[0m         mismatched_keys,\n\u001b[1;32m   4397\u001b[0m         offload_index,\n\u001b[1;32m   4398\u001b[0m         error_msgs,\n\u001b[0;32m-> 4399\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4408\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4417\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4418\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:4822\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4820\u001b[0m \u001b[38;5;66;03m# If shard_file is \"\", we use the existing state_dict instead of loading it\u001b[39;00m\n\u001b[1;32m   4821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 4822\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\n\u001b[1;32m   4824\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4826\u001b[0m \u001b[38;5;66;03m# Fix the key names\u001b[39;00m\n\u001b[1;32m   4827\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {key_renaming_mapping[k]: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key_renaming_mapping}\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/transformers/modeling_utils.py:556\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(checkpoint_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m map_location \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_zipfile(checkpoint_file)\n\u001b[1;32m    554\u001b[0m     ):\n\u001b[1;32m    555\u001b[0m         extra_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/j_knnee/lib/python3.10/site-packages/torch/serialization.py:1264\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m deserialized_objects\n\u001b[1;32m   1263\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m deserialized_objects[key]\n\u001b[0;32m-> 1264\u001b[0m \u001b[43mtyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_untyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_should_read_directly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_element_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1268\u001b[0m     offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setting\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, output_hidden_states=True).eval().to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertModel, BertConfig, BertForSequenceClassification\n",
    "# import torch.nn as nn\n",
    "# import torch\n",
    "\n",
    "# class CustomBertSmall(nn.Module):\n",
    "#     def __init__(self, teacher_model, total_layers=6, transplanted_layers=3):\n",
    "#         super().__init__()\n",
    "#         assert transplanted_layers < total_layers, \"Transplanted layers must be fewer than total layers\"\n",
    "        \n",
    "#         self.hidden_size = teacher_model.config.hidden_size\n",
    "#         self.total_layers = total_layers\n",
    "#         self.transplanted_layers = transplanted_layers\n",
    "\n",
    "#         # 그대로 복사할 레이어 인덱스 계산\n",
    "#         transplanted_start = 12 - transplanted_layers\n",
    "#         original_layer_indices = list(range(transplanted_start))[:total_layers - transplanted_layers]\n",
    "\n",
    "#         # Embedding 복사\n",
    "#         self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "#         # 선택된 layer만 복사해서 재구성\n",
    "#         self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "#         for idx in original_layer_indices:\n",
    "#             layer = teacher_model.bert.encoder.layer[idx]\n",
    "#             self.encoder_layers.append(layer)\n",
    "\n",
    "#         for idx in range(transplanted_start, 12):\n",
    "#             layer = teacher_model.bert.encoder.layer[idx]\n",
    "#             self.encoder_layers.append(layer)\n",
    "\n",
    "#         # Pooler와 Classifier도 복사\n",
    "#         self.pooler = teacher_model.bert.pooler\n",
    "#         self.dropout = teacher_model.dropout  # from classifier head\n",
    "#         self.classifier = teacher_model.classifier\n",
    "\n",
    "#         self.activation = nn.Tanh()  # 여전히 pooler 내부에서도 사용되지만 보존\n",
    "\n",
    "#     # CustomBertSmall에 hidden_states 옵션 추가\n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "#         hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "#         if attention_mask is not None:\n",
    "#             extended_attention_mask = attention_mask[:, None, None, :]\n",
    "#             extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "#         else:\n",
    "#             extended_attention_mask = None\n",
    "\n",
    "#         all_hidden = []  # 각 레이어 출력 저장\n",
    "#         for layer in self.encoder_layers:\n",
    "#             hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "#             if output_hidden_states:\n",
    "#                 all_hidden.append(hidden_states)\n",
    "\n",
    "#         pooled_output = self.pooler(hidden_states)\n",
    "#         pooled_output = self.dropout(self.activation(pooled_output))\n",
    "#         logits = self.classifier(pooled_output)\n",
    "\n",
    "#         if output_hidden_states:\n",
    "#             return logits, all_hidden\n",
    "#         else:\n",
    "#             return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomBertSmallForCKA(nn.Module):\n",
    "    def __init__(self, teacher_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = teacher_model.config.hidden_size\n",
    "        self.selected_layer_indices = [0, 1, 2, 3, 4, 11]   # 1-based: [1,2,3,4,5,12] → 0-based index\n",
    "\n",
    "        # Embedding 복사\n",
    "        self.embeddings = teacher_model.bert.embeddings\n",
    "\n",
    "        # 선택된 레이어만 복사\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            teacher_model.bert.encoder.layer[idx] for idx in self.selected_layer_indices\n",
    "        ])\n",
    "\n",
    "        # Pooler와 Classifier는 그대로 복사\n",
    "        self.pooler = teacher_model.bert.pooler\n",
    "        self.dropout = teacher_model.dropout\n",
    "        self.classifier = teacher_model.classifier\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, output_hidden_states=False):\n",
    "        hidden_states = self.embeddings(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            extended_attention_mask = attention_mask[:, None, None, :]\n",
    "            extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            extended_attention_mask = None\n",
    "\n",
    "        all_hidden = []\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)[0]\n",
    "            if output_hidden_states:\n",
    "                all_hidden.append(hidden_states)\n",
    "\n",
    "        pooled_output = self.pooler(hidden_states)\n",
    "        pooled_output = self.dropout(self.activation(pooled_output))\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            return logits, all_hidden\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# model_name = \"textattack/bert-base-uncased-ag-news\"\n",
    "\n",
    "teacher_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "small_model = CustomBertSmallForCKA(\n",
    "    teacher_model=teacher_model \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [check] before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for accuracy with QQP task\n",
    "# correct_base = 0\n",
    "# correct_small = 0\n",
    "\n",
    "# model.eval()\n",
    "# small_model.eval()\n",
    "\n",
    "# for item in tqdm(val_dataset, desc=\"Evaluating Small Model (QQP)\"):\n",
    "#     text1 = item[\"sentence1\"]\n",
    "#     text2 = item[\"sentence2\"]\n",
    "#     label = item[\"label\"]\n",
    "\n",
    "#     # inputs for sentence pair\n",
    "#     inputs = tokenizer(text1, text2, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "#     # Teacher model\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**inputs)\n",
    "#         logits = output.logits\n",
    "#         pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "#     # Small model\n",
    "#     with torch.no_grad():\n",
    "#         small_logits = small_model(**inputs)\n",
    "#         small_pred = torch.argmax(small_logits, dim=-1).item()\n",
    "\n",
    "#     correct_base += int(pred == label)\n",
    "#     correct_small += int(small_pred == label)\n",
    "\n",
    "# # 최종 정확도 출력\n",
    "# total = len(val_dataset)\n",
    "# print(f\"\\n✅ Accuracy of Bertbase: {correct_base / total * 100:.2f}%\")\n",
    "# print(f\"\\n✅ Accuracy of CustomBertSmall: {correct_small / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import MSELoss, KLDivLoss\n",
    "\n",
    "def loss1(logits, labels):\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# Representation Matching Loss (MSE between CLS tokens)\n",
    "def loss2(student_hidden, teacher_hidden):\n",
    "    mse = MSELoss()\n",
    "    return mse(student_hidden, teacher_hidden)\n",
    "\n",
    "# DSR Loss (KL Divergence between sorted logits)\n",
    "def loss3(prev_logits, current_logits, tau=1.0):\n",
    "    z_prev = torch.sort(prev_logits, dim=-1)[0]\n",
    "    z_current = torch.sort(current_logits, dim=-1)[0]\n",
    "\n",
    "    p_prev = F.softmax(z_prev / tau, dim=-1)\n",
    "    p_current = F.log_softmax(z_current / tau, dim=-1)\n",
    "\n",
    "    kldiv = KLDivLoss(reduction='batchmean')\n",
    "    return (tau ** 2 / 2) * kldiv(p_current, p_prev)  # KL(p_prev || p_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cka(X: torch.Tensor, Y: torch.Tensor, eps=1e-8):\n",
    "    X = X - X.mean(dim=0, keepdim=True)\n",
    "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "\n",
    "    dot_product_similarity = (X.T @ Y).norm(p='fro') ** 2\n",
    "    normalization_x = (X.T @ X).norm(p='fro')\n",
    "    normalization_y = (Y.T @ Y).norm(p='fro')\n",
    "    return dot_product_similarity / (normalization_x * normalization_y + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, tokenizer, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            text1 = batch[\"sentence1\"][0]\n",
    "            text2 = batch[\"sentence2\"][0]\n",
    "            label = batch[\"label\"].item()\n",
    "\n",
    "            inputs = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            logits = model(**inputs)\n",
    "            pred = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "            correct += int(pred == label)\n",
    "            total += 1\n",
    "\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_teacher_layers(n_student_layers, n_teacher_layers=12):\n",
    "    return np.linspace(1, n_teacher_layers, n_student_layers, dtype=int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_cka_loss_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    teacher_model=None,\n",
    "    custom_loss=False,  # CKA 전용 loss\n",
    "    strategy=\"freeze\",\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    base_lr=5e-5,\n",
    "    low_lr=5e-6,\n",
    "    k=3,\n",
    "    alpha=1.0,  # alpha는 의미 없음, loss = cka_loss 단일\n",
    "    unfreeze_epoch=1,\n",
    "    save_path=\"best_model.pt\",\n",
    "    device=\"cuda:1\" if torch.cuda.is_available() else \"cpu\",\n",
    "    evaluate_fn=None,\n",
    "    task_config=None\n",
    "):\n",
    "    if task_config is None:\n",
    "        raise ValueError(\"task_config must be provided.\")\n",
    "    if custom_loss and teacher_model is None:\n",
    "        raise ValueError(\"teacher_model must be provided when using custom_loss=True\")\n",
    "    if evaluate_fn is None:\n",
    "        raise ValueError(\"evaluate_fn must be provided for evaluation\")\n",
    "\n",
    "    input_keys = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    model = model.to(device)\n",
    "    teacher_model = teacher_model.to(device) if teacher_model else None\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "    if strategy == \"low_lr\":\n",
    "        optimizer_grouped = [\n",
    "            {\"params\": model.encoder_layers[0].parameters(), \"lr\": low_lr},   # ⬅️ 첫 번째 레이어\n",
    "            {\"params\": model.encoder_layers[-1].parameters(), \"lr\": low_lr},  # ⬅️ 마지막 레이어\n",
    "            {\"params\": [p for l in model.encoder_layers[1:-1] for p in l.parameters()], \"lr\": base_lr},\n",
    "            {\"params\": model.pooler.parameters(), \"lr\": base_lr},\n",
    "            {\"params\": model.classifier.parameters(), \"lr\": base_lr},\n",
    "        ]\n",
    "    else:\n",
    "        optimizer_grouped = model.parameters()  \n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped, lr=base_lr)\n",
    "\n",
    "    # 기본 loss는 CE지만, custom_loss=True일 경우 사용 안 함\n",
    "    loss_fn = nn.MSELoss() if task_type == \"regression\" else nn.CrossEntropyLoss()\n",
    "\n",
    "    if strategy == \"freeze\":\n",
    "        for layer in model.encoder_layers[-k:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    best_score = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"\\n📘 Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        if strategy == \"unfreeze\" and epoch == unfreeze_epoch:\n",
    "            print(\"--<Unfreezing last K layers>--\")\n",
    "            for layer in model.encoder_layers[-k:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            # 입력 처리\n",
    "            if len(input_keys) == 2:\n",
    "                texts1 = batch[input_keys[0]]\n",
    "                texts2 = batch[input_keys[1]]\n",
    "                tokenized = tokenizer(list(texts1), list(texts2), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            else:\n",
    "                texts = batch[input_keys[0]]\n",
    "                tokenized = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in tokenized.items()}\n",
    "            labels = batch[label_key].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if custom_loss:\n",
    "                # forward\n",
    "                logits_small, student_hiddens = model(**inputs, output_hidden_states=True)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(**inputs, output_hidden_states=True)\n",
    "                    teacher_hiddens = teacher_outputs.hidden_states  # 13개 (embedding 포함)\n",
    "\n",
    "                # layer 대응\n",
    "                s_h = student_hiddens[1:]  # skip embedding\n",
    "                t_indices = get_matched_teacher_layers(len(s_h), n_teacher_layers=12)\n",
    "                t_h = [teacher_hiddens[i] for i in t_indices]\n",
    "\n",
    "                # CLS 기준으로 CKA loss 계산\n",
    "                loss_cka = 0.0\n",
    "                for t, s in zip(t_h, s_h):\n",
    "                    t_cls = t[:, 0, :]\n",
    "                    s_cls = s[:, 0, :]\n",
    "                    loss_cka += 1 - compute_cka(t_cls, s_cls)\n",
    "                loss_cka /= len(s_h)\n",
    "                loss = loss_cka\n",
    "\n",
    "            else:\n",
    "                logits = model(**inputs)\n",
    "                if task_type == \"regression\":\n",
    "                    labels = labels.float()\n",
    "                    loss = loss_fn(logits.squeeze(), labels)\n",
    "                else:\n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"📉 Avg Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        score = evaluate_fn(model, val_loader, tokenizer, device)\n",
    "        print(f\"📊 Validation Score: {score:.4f}\")\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ Best model saved with score: {best_score:.4f} → {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_TASKS = {\n",
    "    \"sst2\":  {\"inputs\": [\"sentence\"],                     \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-SST-2\"},\n",
    "    \"cola\":  {\"inputs\": [\"sentence\"],                     \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-CoLA\"},\n",
    "    \"qqp\":   {\"inputs\": [\"question1\", \"question2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-QQP\"},\n",
    "    \"qnli\":  {\"inputs\": [\"question\", \"sentence\"],         \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-QNLI\"},\n",
    "    \"mrpc\":  {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-MRPC\"},\n",
    "    \"rte\":   {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"binary\",     \"model\": \"textattack/bert-base-uncased-RTE\"},\n",
    "    \"stsb\":  {\"inputs\": [\"sentence1\", \"sentence2\"],       \"label\": \"label\", \"type\": \"regression\", \"model\": \"textattack/bert-base-uncased-STS-B\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def make_evaluate_fn(task_config):\n",
    "    inputs = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    def evaluate(model, val_loader, tokenizer, device):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "                if len(inputs) == 2:\n",
    "                    text1 = batch[inputs[0]][0]\n",
    "                    text2 = batch[inputs[1]][0]\n",
    "                    encoded = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "                else:\n",
    "                    text = batch[inputs[0]][0]\n",
    "                    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "                encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "                label = batch[label_key].item()\n",
    "                output = model(**encoded)\n",
    "\n",
    "                if task_type == \"regression\":\n",
    "                    pred = output.squeeze().cpu().item()\n",
    "                else:\n",
    "                    pred = torch.argmax(output, dim=-1).item()\n",
    "\n",
    "                preds.append(pred)\n",
    "                labels.append(label)\n",
    "\n",
    "        # 결과 계산\n",
    "        if task_type == \"regression\":\n",
    "            score = pearsonr(preds, labels)[0] * 100  # %\n",
    "        elif task_type in [\"binary\", \"3-class\"]:\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            if len(set(labels)) == 2:\n",
    "                f1 = f1_score(labels, preds)\n",
    "                score = (acc + f1) / 2 * 100\n",
    "            else:\n",
    "                score = acc * 100\n",
    "        else:\n",
    "            raise ValueError(\"Unknown task type\")\n",
    "\n",
    "        return score\n",
    "\n",
    "    return evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "# from loss import cka_delta_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = GLUE_TASKS[task_name]\n",
    "\n",
    "evaluate_fn = make_evaluate_fn(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 147/6547 [00:06<05:04, 21.02it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  32%|███▏      | 2078/6547 [01:25<02:55, 25.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  51%|█████     | 3320/6547 [02:16<02:11, 24.57it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  65%|██████▍   | 4232/6547 [02:54<01:31, 25.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  69%|██████▊   | 4499/6547 [03:05<01:21, 24.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:29<00:00, 24.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 152.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.6077\n",
      "✅ Best model saved with score: 87.6077 → /mnt/aix7101/jeong/ee/qnli_cak.pt\n",
      "\n",
      "📘 Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 651/6547 [00:26<03:58, 24.71it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  77%|███████▋  | 5042/6547 [03:28<01:01, 24.67it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  81%|████████  | 5315/6547 [03:39<00:49, 24.74it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  82%|████████▏ | 5354/6547 [03:41<00:48, 24.56it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  96%|█████████▌| 6284/6547 [04:19<00:10, 24.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:30<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.2530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 152.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.7796\n",
      "✅ Best model saved with score: 87.7796 → /mnt/aix7101/jeong/ee/qnli_cak.pt\n",
      "\n",
      "📘 Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1533/6547 [01:02<03:24, 24.54it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  47%|████▋     | 3081/6547 [02:06<02:21, 24.50it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  63%|██████▎   | 4103/6547 [02:49<01:38, 24.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  76%|███████▌  | 4946/6547 [03:24<01:04, 24.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  96%|█████████▌| 6288/6547 [04:20<00:10, 24.46it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:30<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 152.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.5264\n",
      "\n",
      "📘 Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 288/6547 [00:11<04:12, 24.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  28%|██▊       | 1809/6547 [01:14<03:09, 25.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  52%|█████▏    | 3390/6547 [02:20<02:30, 20.99it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  56%|█████▌    | 3644/6547 [02:31<02:00, 24.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  79%|███████▉  | 5160/6547 [03:34<00:57, 24.28it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:33<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 153.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 86.1633\n",
      "\n",
      "📘 Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 1735/6547 [01:11<03:34, 22.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  56%|█████▌    | 3634/6547 [02:30<02:00, 24.17it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  68%|██████▊   | 4426/6547 [03:04<01:26, 24.52it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  73%|███████▎  | 4780/6547 [03:18<01:10, 25.08it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  84%|████████▍ | 5488/6547 [03:48<00:42, 25.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:31<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 152.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.1776\n",
      "\n",
      "📘 Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 1478/6547 [01:01<03:26, 24.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  37%|███▋      | 2424/6547 [01:40<02:46, 24.72it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  40%|████      | 2640/6547 [01:49<02:39, 24.47it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  45%|████▌     | 2969/6547 [02:03<02:26, 24.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  86%|████████▌ | 5622/6547 [03:54<00:37, 24.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:33<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:36<00:00, 151.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.1403\n",
      "\n",
      "📘 Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 1250/6547 [00:52<03:28, 25.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  68%|██████▊   | 4474/6547 [03:08<01:23, 24.70it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  75%|███████▍  | 4879/6547 [03:24<01:06, 25.10it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  87%|████████▋ | 5668/6547 [03:58<00:34, 25.19it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  98%|█████████▊| 6397/6547 [04:28<00:06, 23.24it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:34<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:36<00:00, 150.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.0171\n",
      "\n",
      "📘 Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 1628/6547 [01:08<03:52, 21.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  25%|██▌       | 1653/6547 [01:09<03:41, 22.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  66%|██████▌   | 4323/6547 [03:00<01:32, 24.12it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  81%|████████  | 5307/6547 [03:42<00:49, 25.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  89%|████████▉ | 5819/6547 [04:03<00:32, 22.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:34<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:36<00:00, 151.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 86.7216\n",
      "\n",
      "📘 Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 675/6547 [00:27<03:59, 24.49it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  29%|██▉       | 1886/6547 [01:18<03:18, 23.45it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  81%|████████  | 5281/6547 [03:38<00:50, 25.14it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  85%|████████▌ | 5584/6547 [03:51<00:39, 24.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  89%|████████▉ | 5850/6547 [04:02<00:29, 23.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:31<00:00, 24.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 153.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 86.8777\n",
      "\n",
      "📘 Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 1647/6547 [01:07<03:39, 22.37it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  37%|███▋      | 2397/6547 [01:38<02:44, 25.16it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  48%|████▊     | 3165/6547 [02:10<02:19, 24.26it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  60%|██████    | 3929/6547 [02:42<01:58, 22.05it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training:  76%|███████▋  | 5002/6547 [03:28<01:02, 24.86it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training: 100%|██████████| 6547/6547 [04:32<00:00, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Avg Training Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5463/5463 [00:35<00:00, 152.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation Score: 87.3821\n"
     ]
    }
   ],
   "source": [
    "train_cka_loss_model(\n",
    "    model=small_model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    teacher_model=model,\n",
    "    custom_loss=False,\n",
    "    strategy=\"low_lr\",\n",
    "    batch_size=16,\n",
    "    epochs=num_epoch,\n",
    "    k=trans_l,\n",
    "    unfreeze_epoch=num_unfreeze,\n",
    "    save_path=model_save_path,\n",
    "    evaluate_fn=evaluate_fn,\n",
    "    task_config=task_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "#-- load trained model\n",
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "small_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "small_model = small_model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_teacher_student(\n",
    "    teacher_model,\n",
    "    student_model,\n",
    "    val_dataset,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    task_config,\n",
    "    task_name=None  # 👈 task 이름 추가로 받음 (cola 확인용)\n",
    "):\n",
    "    inputs_key = task_config[\"inputs\"]\n",
    "    label_key = task_config[\"label\"]\n",
    "    task_type = task_config[\"type\"]\n",
    "\n",
    "    teacher_model.eval()\n",
    "    student_model.eval()\n",
    "\n",
    "    preds_teacher = []\n",
    "    preds_student = []\n",
    "    labels = []\n",
    "\n",
    "    for item in tqdm(val_dataset, desc=\"Evaluating Teacher vs Student\"):\n",
    "        if len(inputs_key) == 2:\n",
    "            input_text1 = item[inputs_key[0]]\n",
    "            input_text2 = item[inputs_key[1]]\n",
    "            tokenized = tokenizer(input_text1, input_text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        else:\n",
    "            input_text = item[inputs_key[0]]\n",
    "            tokenized = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "        label = item[label_key]\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.item()\n",
    "        labels.append(label)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_logits = teacher_model(**tokenized)\n",
    "            t_pred = t_logits.logits.squeeze().item() if task_type == \"regression\" else torch.argmax(t_logits.logits, dim=-1).item()\n",
    "\n",
    "            s_logits = student_model(**tokenized)\n",
    "            s_pred = s_logits.squeeze().item() if task_type == \"regression\" else torch.argmax(s_logits, dim=-1).item()\n",
    "\n",
    "        preds_teacher.append(t_pred)\n",
    "        preds_student.append(s_pred)\n",
    "\n",
    "    # 🎯 점수 계산\n",
    "    if task_type == \"regression\":\n",
    "        pearson_t = pearsonr(preds_teacher, labels)[0] * 100\n",
    "        pearson_s = pearsonr(preds_student, labels)[0] * 100\n",
    "        print(f\"\\n✅ Pearson of Teacher: {pearson_t:.2f}%\")\n",
    "        print(f\"✅ Pearson of Student: {pearson_s:.2f}%\")\n",
    "\n",
    "    elif task_name == \"cola\":\n",
    "        mcc_t = matthews_corrcoef(labels, preds_teacher) * 100\n",
    "        mcc_s = matthews_corrcoef(labels, preds_student) * 100\n",
    "        print(f\"\\n✅ MCC of Teacher: {mcc_t:.2f}%\")\n",
    "        print(f\"✅ MCC of Student: {mcc_s:.2f}%\")\n",
    "\n",
    "    else:\n",
    "        acc_t = accuracy_score(labels, preds_teacher) * 100\n",
    "        acc_s = accuracy_score(labels, preds_student) * 100\n",
    "        print(f\"\\n✅ Accuracy of Teacher: {acc_t:.2f}%\")\n",
    "        print(f\"✅ Accuracy of Student: {acc_s:.2f}%\")\n",
    "    return acc_t, acc_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Teacher vs Student: 100%|██████████| 5463/5463 [01:26<00:00, 63.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy of Teacher: 91.54%\n",
      "✅ Accuracy of Student: 87.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91.54310818231741, 87.60754164378547)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_teacher_student(\n",
    "    teacher_model=model,\n",
    "    student_model=small_model,\n",
    "    val_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    task_config=task_config,\n",
    "    task_name=task_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
