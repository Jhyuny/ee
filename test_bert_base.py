from datasets import load_dataset
from transformers import BertTokenizer, BertForSequenceClassification
import torch
from torch.nn.functional import softmax
import pandas as pd
from tqdm import tqdm
import os

# Fine-tuned SST-2 ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
model_name = "JeremiahZ/bert-base-uncased-sst2"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)

# classification module
print("-"*20)
print(model.classifier)
print("-"*20)
model.eval()

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# SST-2 validation ë°ì´í„° ë¡œë“œ
dataset = load_dataset("glue", "sst2", split="validation")

# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
results = []

for item in tqdm(dataset, desc="Running SST-2 predictions"):
    text = item["sentence"]
    label = item["label"]

    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)

    with torch.no_grad():
        outputs = model(**inputs)
        probs = softmax(outputs.logits, dim=-1)
        pred = torch.argmax(probs, dim=-1).item()

    correct = int(pred == label)

    results.append({
        "Sentence": text,
        "ModelOutput": pred,
        "Label": label,
        "Correct": correct
    })

# CSVë¡œ ì €ì¥
df = pd.DataFrame(results)
os.makedirs("results", exist_ok=True)
df.to_csv("results/sst2_finetuned_predictions.csv", index=False)

# ì •í™•ë„ ì¶œë ¥
accuracy = df["Correct"].mean() * 100
print(f"\nâœ… SST-2 Accuracy (fine-tuned BERT): {accuracy:.2f}%")
print("ğŸ“ 'results/sst2_finetuned_predictions.csv'ì— ì €ì¥ ì™„ë£Œ!")